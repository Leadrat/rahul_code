{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c83a8d61",
   "metadata": {},
   "source": [
    "# EDA, Feature Engineering and Training â€” Example Notebook\n",
    "\n",
    "This notebook provides a compact, runnable example that demonstrates:\n",
    "\n",
    "- Generating a synthetic tabular dataset\n",
    "- Performing quick exploratory data analysis (EDA)\n",
    "- Applying common feature engineering transformations\n",
    "- Training a LightGBM model and evaluating it\n",
    "- Optionally logging the run with MLflow and saving a model artifact\n",
    "\n",
    "Notes: this is intended as a minimal, self-contained example you can run locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af17e1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Optional: MLflow logging (if available)\n",
    "try:\n",
    "    import mlflow\n",
    "    MLFLOW_AVAILABLE = True\n",
    "except Exception:\n",
    "    MLFLOW_AVAILABLE = False\n",
    "\n",
    "print('numpy', np.__version__, 'pandas', pd.__version__, 'lightgbm', lgb.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84945dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a synthetic classification dataset with a few categorical and datetime-like features\n",
    "X, y = make_classification(n_samples=5000, n_features=8, n_informative=4, n_redundant=1, random_state=42)\n",
    "df = pd.DataFrame(X, columns=[f\"feat_{i}\" for i in range(X.shape[1])])\n",
    "df['target'] = y\n",
    "\n",
    "# Add a synthetic datetime (event_time) and a categorical column\n",
    "rng = pd.date_range('2022-01-01', periods=len(df), freq='T')\n",
    "df['event_time'] = rng.to_series().sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "df['user_tier'] = np.random.choice(['free', 'pro', 'enterprise'], size=len(df), p=[0.7,0.25,0.05])\n",
    "\n",
    "# Add some missing values deliberately\n",
    "df.loc[df.sample(frac=0.03, random_state=2).index, 'feat_0'] = np.nan\n",
    "df.loc[df.sample(frac=0.02, random_state=3).index, 'user_tier'] = None\n",
    "\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44cb051",
   "metadata": {},
   "source": [
    "## Quick EDA\n",
    "We'll check shape, summary statistics, missingness, distributions, and simple correlations. These quick checks help us form hypotheses about useful features and potential data issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece4b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shape:', df.shape)\n",
    "print('\n",
    "missing per column:\n",
    "', df.isna().mean())\n",
    "print('\n",
    "summary stats for numeric cols:\n",
    "')\n",
    "display(df.describe().T)\n",
    "\n",
    "# Correlation heatmap (numeric features)\n",
    "corr = df.select_dtypes(include=[np.number]).corr()\n",
    "print('\n",
    "Top correlations with target:')\n",
    "print(corr['target'].abs().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5042885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small visual checks (matplotlib/seaborn) -- inline plots in notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(df['feat_0'].dropna(), kde=True)\n",
    "plt.title('Distribution of feat_0 (with missing values)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(corr, annot=False, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation matrix (numeric)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c76d10",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "We'll create features commonly useful in production: datetime-derived features, categorical encodings, missing indicators, interaction features, and scaling for models that need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39dd585",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = df.copy()\n",
    "# datetime features\n",
    "df_fe['event_hour'] = df_fe['event_time'].dt.hour\n",
    "df_fe['event_dayofweek'] = df_fe['event_time'].dt.dayofweek\n",
    "df_fe['is_weekend'] = df_fe['event_dayofweek'].isin([5,6]).astype(int)\n",
    "\n",
    "# missing indicator\n",
    "df_fe['feat_0_missing'] = df_fe['feat_0'].isna().astype(int)\n",
    "# simple imputation for numeric\n",
    "df_fe['feat_0'] = df_fe['feat_0'].fillna(df_fe['feat_0'].median())\n",
    "\n",
    "# target (mean) encoding for user_tier (simple out-of-fold is preferred in production)\n",
    "tier_means = df_fe.groupby('user_tier')['target'].mean()\n",
    "df_fe['user_tier_mean_target'] = df_fe['user_tier'].map(tier_means).fillna(df_fe['target'].mean())\n",
    "\n",
    "# interaction feature example\n",
    "df_fe['feat_0_x_feat_1'] = df_fe['feat_0'] * df_fe['feat_1']\n",
    "\n",
    "# Numeric scaling for models that need it\n",
    "num_cols = [c for c in df_fe.columns if c.startswith('feat_')]\n",
    "scaler = StandardScaler()\n",
    "df_fe[num_cols] = scaler.fit_transform(df_fe[num_cols])\n",
    "\n",
    "df_fe.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e93455",
   "metadata": {},
   "source": [
    "## Train / Test split and Model Training\n",
    "We'll split by time if this were a temporal problem; for this synthetic example we do a random split. We'll then train LightGBM and evaluate ROC AUC and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b528fcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare feature matrix\n",
    "features = [c for c in df_fe.columns if c not in ('target','event_time','user_tier')]\n",
    "X = df_fe[features]\n",
    "y = df_fe['target']\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# LightGBM dataset and params\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': ['auc','binary_logloss'],\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "bst = lgb.train(params, train_data, num_boost_round=200, valid_sets=[train_data, valid_data], early_stopping_rounds=20, verbose_eval=False)\n",
    "\n",
    "# predictions and evaluation\n",
    "y_pred_proba = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "print('ROC AUC:', round(roc_auc_score(y_test, y_pred_proba), 4))\n",
    "print('Accuracy:', round(accuracy_score(y_test, y_pred), 4))\n",
    "print('\n",
    "Classification report:\n",
    "', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75b85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: log to MLflow if available\n",
    "if MLFLOW_AVAILABLE:\n",
    "    mlflow.set_experiment('eda_feature_training_example')\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params({'model': 'lightgbm', 'num_leaves': 31, 'learning_rate': 0.05})\n",
    "        mlflow.log_metric('roc_auc', float(roc_auc_score(y_test, y_pred_proba)))\n",
    "        mlflow.log_metric('accuracy', float(accuracy_score(y_test, y_pred)))\n",
    "        # save model artifact\n",
    "        model_path = 'models/lightgbm_example.txt'\n",
    "        os.makedirs('models', exist_ok=True)\n",
    "        bst.save_model(model_path)\n",
    "        mlflow.log_artifact(model_path)\n",
    "        print('Logged run to MLflow')\n",
    "else:\n",
    "    print('MLflow not available in this environment; skipping MLflow logging')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb1b2f8",
   "metadata": {},
   "source": [
    "## Save model locally and simple inference example\n",
    "We'll persist a scikit-compatible artifact with joblib and load it back for scoring. In production you'd use a model server or BentoML / Seldon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a26170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save with joblib (wrapping LightGBM booster for convenience)\n",
    "model_artifact = 'models/lgb_model.joblib'\n",
    "os.makedirs('models', exist_ok=True)\n",
    "joblib.dump({'booster': bst, 'features': features, 'scaler': scaler}, model_artifact)\n",
    "print('Saved model to', model_artifact)\n",
    "\n",
    "# Load and run a quick prediction\n",
    "loaded = joblib.load(model_artifact)\n",
    "booster = loaded['booster']\n",
    "sample_X = X_test.iloc[:5]\n",
    "print('Sample predictions:', booster.predict(sample_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1171a905",
   "metadata": {},
   "source": [
    "## Next steps and production notes\n",
    "- Replace synthetic data with real datasets and prefer time-aware splitting for temporal data.\n",
    "- Use out-of-fold target encoding and cross-validated feature calculations.\n",
    "- Materialize features in a feature store for parity between training and serving (Feast).\n",
    "- Add unit tests for transformations and data quality checks with Great Expectations."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
